# DVEPS-Lite
DVEPS-Lite

This project is an autonomous drone that flies to a destination provided by a user from a ground control station. The drone then uses camera and LiDAR sensory information to detect and avoid any obstacles in its path. This project is part of an interdisciplinary senior design course (ENGR 498) and contains 7 total team members: 2 software engineers, 2 optical engineers, 1 electrical and computer engineer, and 2 mechanical/aerospace engineers.

The embedded system for this drone consists of 5 main parts: The drone kit, the flight controller (Pixhawk), the on-board processor (Jetson Orin Nano), the Camera, and the LiDAR. The camera will feed video frames to the on-board processor which will be processed using image analysis methods via the OpenCV library to detect and outline objects. Similarly, the LiDAR will return a series of 1D points containing distance and angle which will be organized to make up a cross-air pointed at the center of the drone's hit box. Both of these sets of sensory data will be processed by the on-board processor then a decision will be made on whether the drone needs to stop and reroute or not. This decision will be sent from the on-board processor to the flight controller which controls the motors of the drone. Simultaneously, telemetry data will be sent back to the ground control station for the user to view. This telemetry will include important flight information such as the video feed, lidar data, and drone location.
